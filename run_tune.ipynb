{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from mosaic_sdf import MosaicSDF\n",
    "from shape_sampler import ShapeSampler\n",
    "from optimizer import MosaicSDFOptimizer\n",
    "from mosaic_sdf_visualizer import MosaicSDFVisualizer\n",
    "\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_mesh_path = 'data/cube.obj'\n",
    "teapot_mesh_path = 'data/utah_teapot.obj'\n",
    "cow_mesh_path = 'data/cow_mesh/cow.obj'\n",
    "\n",
    "cube_wireframe_path = 'data/cube_wireframe.obj'\n",
    "\n",
    "sdf_shape_path = teapot_mesh_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import os\n",
    "\n",
    "\n",
    "config = {   \n",
    "    'device': device,\n",
    "    # 'shape_sampler': shape_sampler,  # Adjust accordingly\n",
    "    'shape_path': os.path.abspath(sdf_shape_path),  # Adjust accordingly\n",
    "    \n",
    "    # mosaicSDF params\n",
    "    'grid_resolution': 7,\n",
    "    # 'n_grids': 1024,\n",
    "    'n_grids': 128,\n",
    "    # 'n_grids': 8,\n",
    "    'points_random_spread': .03,\n",
    "    'mosaic_scale_multiplier': 3,\n",
    "    \n",
    "    # optimizer params\n",
    "    # TODO play with Adam params\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    # \"b1\": tune.quniform(0.4, 0.8, .2),\n",
    "\n",
    "    # lerp between l1 and l2 losses\n",
    "    'lambda_val': .1,\n",
    "    \n",
    "    \n",
    "    # optimization params\n",
    "    # 'n_epochs':  tune.choice([1, 4, 8, 16]),\n",
    "    # 'n_epochs':  tune.grid([ 8 ]),\n",
    "    \n",
    "    'n_epochs':  2,\n",
    "\n",
    "    'points_in_epoch': 2048,\n",
    "    'points_sample_size': 32,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "\n",
    "    'eval_every_nth_points': 256,\n",
    "    'val_size': 512,\n",
    "    'points_sample_size_eval_scaler': 4, # can sample faster during eval\n",
    "\n",
    "    'project_name': 'mosaicSDF_smoke',\n",
    "    'log_to_wandb': True, \n",
    "\n",
    "    # other debug stuff\n",
    "    'output_graph': False,\n",
    "    'points_random_sampling': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-13 08:18:27</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:33.85        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.0/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 40.000: None | Iter 10.000: None<br>Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  step</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_l1_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>MosaicSDFOptimizer_6ce91_00000</td><td>TERMINATED</td><td>172.17.95.129:93567</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         24.3812</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">   0.0137972</td><td style=\"text-align: right;\">     0.00624069</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m /home/che/miniforge3/envs/gen3d/lib/python3.10/site-packages/point_cloud_utils/_mesh_io.py:338: RuntimeWarning: TinyObjReader: Empty group name. line: 6\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Empty group name. line: 6475\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m   mesh_dict = load_mesh_internal(mesh_filename, dtype)\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: Currently logged in as: acherednychenko. Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: Tracking run with wandb version 0.16.4\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: Run data is saved locally in /home/che/ray_results/mosaicSDF_smoke/MosaicSDFOptimizer_6ce91_00000_0_2024-03-13_08-17-53/wandb/run-20240313_081758-w5ineek5\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: Syncing run jolly-blaze-5\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/acherednychenko/mosaicSDF_smoke\n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m wandb: üöÄ View run at https://wandb.ai/acherednychenko/mosaicSDF_smoke/runs/w5ineek5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 7, val Loss: 0.0087, val L1: 0.0057, val L2: 0.0361 ||| train Loss: 0.0129 train L1: 0.0055, train L2: 0.0804 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 15, val Loss: 0.0088, val L1: 0.0057, val L2: 0.0362 ||| train Loss: 0.0124 train L1: 0.0061, train L2: 0.0690 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 23, val Loss: 0.0088, val L1: 0.0057, val L2: 0.0362 ||| train Loss: 0.0130 train L1: 0.0062, train L2: 0.0738 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 31, val Loss: 0.0087, val L1: 0.0057, val L2: 0.0362 ||| train Loss: 0.0123 train L1: 0.0064, train L2: 0.0649 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 39, val Loss: 0.0087, val L1: 0.0057, val L2: 0.0361 ||| train Loss: 0.0136 train L1: 0.0065, train L2: 0.0776 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 47, val Loss: 0.0087, val L1: 0.0057, val L2: 0.0360 ||| train Loss: 0.0141 train L1: 0.0078, train L2: 0.0710 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 55, val Loss: 0.0087, val L1: 0.0057, val L2: 0.0360 ||| train Loss: 0.0123 train L1: 0.0055, train L2: 0.0736 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/che/code/ml/gen3d/research/mosaicSDF/out/tune/mosaicSDF_smoke/mosaicSDF_smoke/MosaicSDFOptimizer_6ce91_00000_0_2024-03-13_08-17-53/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 63, val Loss: 0.0088, val L1: 0.0057, val L2: 0.0361 ||| train Loss: 0.0142 train L1: 0.0066, train L2: 0.0830 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 7, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0368 ||| train Loss: 0.0130 train L1: 0.0048, train L2: 0.0860 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 15, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0370 ||| train Loss: 0.0135 train L1: 0.0069, train L2: 0.0725 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 23, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0370 ||| train Loss: 0.0136 train L1: 0.0075, train L2: 0.0682 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 31, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0370 ||| train Loss: 0.0133 train L1: 0.0063, train L2: 0.0766 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 39, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0368 ||| train Loss: 0.0151 train L1: 0.0070, train L2: 0.0882 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 47, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0366 ||| train Loss: 0.0125 train L1: 0.0065, train L2: 0.0666 \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 55, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0369 ||| train Loss: 0.0118 train L1: 0.0045, train L2: 0.0770 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 08:18:27,210\tINFO tune.py:1042 -- Total run time: 33.86 seconds (33.81 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.train import RunConfig, CheckpointConfig\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray.data import DataContext\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "# from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "# mlflow_tracking_uri = \"http://localhost:5000\"\n",
    "\n",
    "driver_ctx = DataContext.get_current()\n",
    "\n",
    "trainable_with_resources = tune.with_resources(MosaicSDFOptimizer, {\"cpu\": 10, \"gpu\": 1})\n",
    "\n",
    "wb_exclude = ['training_iteration',\n",
    "              'timestamp',\n",
    "              'time_since_restore',\n",
    "              'iterations_since_restore']\n",
    "\n",
    "tune_storage_path = f\"./out/tune/{config['project_name']}\"\n",
    "tune_storage_path = os.path.abspath(tune_storage_path)\n",
    "\n",
    "# experiment_name = 'mosaic_sdf_smoke'\n",
    "\n",
    "# print(f\"experiment_name: {experiment_name}\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    run_config=RunConfig(\n",
    "        storage_path=tune_storage_path, \n",
    "        name=config['project_name'],\n",
    "        stop={\"training_iteration\": config['n_epochs']},\n",
    "        callbacks= [\n",
    "         #   WandbLoggerCallback(project=\"hello_tune\", excludes=wb_exclude),\n",
    "            # MLflowLoggerCallback(\n",
    "            #         tracking_uri=mlflow_tracking_uri,\n",
    "            #         experiment_name=experiment_name,\n",
    "            #         save_artifact=False,\n",
    "            #     )\n",
    "         ],\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=10,\n",
    "            checkpoint_frequency=1, \n",
    "            checkpoint_at_end=True\n",
    "        )),\n",
    "    \n",
    "    tune_config=tune.TuneConfig(\n",
    "        # num_samples=1,\n",
    "        # metric=\"test_loss_pixel\", \n",
    "        # mode=\"min\",\n",
    "        max_concurrent_trials=1,\n",
    "        # search_alg=algo,\n",
    "        scheduler=ASHAScheduler(metric='val_loss', mode=\"min\", grace_period=10),\n",
    "    ),\n",
    "    # param_space=train_config if continue_tune else tuning_config,\n",
    "    param_space=config\n",
    ")\n",
    "\n",
    "\n",
    "continue_tune = False\n",
    "if not continue_tune:\n",
    "    results = tuner.fit()\n",
    "else:\n",
    "    print('resuming')\n",
    "    restored_tuner = tune.Tuner.restore(\n",
    "        Checkpoint.from_directory(os.path.join(tune_storage_path, config['project_name'])).path,\n",
    "        trainable=trainable_with_resources,\n",
    "        # Re-specify the `param_space` to update the object references.\n",
    "        param_space=config,\n",
    "        resume_unfinished=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m \n",
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Iteration 63, val Loss: 0.0089, val L1: 0.0058, val L2: 0.0369 ||| train Loss: 0.0138 train L1: 0.0062, train L2: 0.0818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MosaicSDFOptimizer pid=93567)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/che/code/ml/gen3d/research/mosaicSDF/out/tune/mosaicSDF_smoke/mosaicSDF_smoke/MosaicSDFOptimizer_6ce91_00000_0_2024-03-13_08-17-53/checkpoint_000001)\n"
     ]
    }
   ],
   "source": [
    "optimizer = None # load optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer = MosaicSDFVisualizer(optimizer.model, optimizer.shape_sampler, \n",
    "    device, template_mesh_path=cube_wireframe_path)#, requires_grad=False)\n",
    "\n",
    "# visualizer.plot_meshes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_sampler = ShapeSampler.from_file(sdf_shape_path, device='cuda')\n",
    "\n",
    "def compare_shapes(resolution = 32, show_mosaic_grids = False):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        gt_sdf_mesh = MosaicSDFVisualizer.rasterize_sdf(\n",
    "            sdf_func=shape_sampler.forward, resolution=resolution, sdf_scaler=-1, \n",
    "            extra_sdf_offset=[2,0, 0], vert_colors=[0, .5, 0])\n",
    "\n",
    "        gt_mesh = visualizer.create_state_meshes(\n",
    "            show_mosaic_grids=False,\n",
    "            show_target_mesh=True,\n",
    "            show_boundary_mesh=False,\n",
    "            resolution=resolution,\n",
    "            show_rasterized_sdf_mesh=False,\n",
    "            vert_colors=[0, 0, .5],\n",
    "            offset_vertices=torch.tensor([-2,0,0], device=device)\n",
    "            )\n",
    "        \n",
    "        meshes = visualizer.create_state_meshes(\n",
    "            show_mosaic_grids=show_mosaic_grids,\n",
    "            show_target_mesh=False,\n",
    "            show_boundary_mesh=False,\n",
    "            resolution=resolution,\n",
    "            vert_colors=[.5, .5, 0]\n",
    "            )\n",
    "        \n",
    "        # Render the plotly figure\n",
    "        fig = plot_scene({\n",
    "            \"subplot1\": {\n",
    "                \"mesh\": meshes,\n",
    "                'gt_sdf_mesh': gt_sdf_mesh,\n",
    "                'gt_mesh': gt_mesh\n",
    "            }\n",
    "        })\n",
    "        fig.show()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_shapes(32, show_mosaic_grids=False)\n",
    "compare_shapes(32, show_mosaic_grids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you're not using a data loader for training\n",
    "optimizer.train()  # Pass None or adjust `train` method to not require `train_loader`\n",
    "\n",
    "\n",
    "\n",
    "# I am also not sure autograd is what we need, how it works in this case at all?\n",
    "\n",
    "# # To save the optimized model\n",
    "# optimizer.save_checkpoint('path/to/save/checkpoint')\n",
    "\n",
    "# # To load an existing model\n",
    "# optimizer.load_checkpoint('path/to/existing/checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_shapes(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     with torch.no_grad():\n",
    "#         meshes = visualizer.create_state_meshes(\n",
    "#             show_mosaic_grids=False,\n",
    "#             show_target_mesh=False,\n",
    "#             resolution=16\n",
    "#             )\n",
    "        \n",
    "#         # Render the plotly figure\n",
    "#         fig = plot_scene({\n",
    "#             \"subplot1\": {\n",
    "#                 \"mesh\": meshes\n",
    "#             }\n",
    "#         })\n",
    "#         fig.show()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     resolution = 8\n",
    "#     grid_points = torch.stack(torch.meshgrid(\n",
    "#             torch.linspace(-1, 1, resolution),\n",
    "#             torch.linspace(-1, 1, resolution),\n",
    "#             torch.linspace(-1, 1, resolution)\n",
    "#         ), dim=-1).reshape(-1, 3)#.to(device)\n",
    "\n",
    "#     sdf_values = optimizer.model(grid_points.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_meshes._verts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage.measure import marching_cubes\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.io import save_obj\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras,\n",
    "    PointLights,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader\n",
    ")\n",
    "mosaic_sdf = optimizer.model\n",
    "resolution = 16\n",
    "\n",
    "# Assuming 'mosaic_sdf' is your MosaicSDF instance and 'resolution' is the desired grid resolution\n",
    "grid_points = torch.stack(torch.meshgrid(\n",
    "    torch.linspace(-1, 1, resolution),\n",
    "    torch.linspace(-1, 1, resolution),\n",
    "    torch.linspace(-1, 1, resolution)\n",
    "), dim=-1).reshape(-1, 3).to(config['device'])\n",
    "\n",
    "# Get the SDF values at these points\n",
    "sdf_values = mosaic_sdf(grid_points).detach().cpu().numpy()\n",
    "sdf_volume = sdf_values.reshape(resolution, resolution, resolution)\n",
    "sdf_volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run marching cubes to get vertices, faces, and normals\n",
    "verts, faces, normals, _ = marching_cubes(sdf_volume, level=0)\n",
    "faces = faces + 1  # skimage has 0-indexed faces, while PyTorch3D expects 1-indexed\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "verts = torch.tensor(verts, dtype=torch.float32)\n",
    "faces = torch.tensor(faces, dtype=torch.int64)\n",
    "\n",
    "# Create a PyTorch3D mesh\n",
    "mesh = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "# Initialize a renderer\n",
    "R, T = look_at_view_transform(2.7, 0, 90)\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
    "raster_settings = RasterizationSettings(image_size=512)\n",
    "lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
    "\n",
    "renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
    "    shader=SoftPhongShader(device=device, cameras=cameras, lights=lights)\n",
    ")\n",
    "\n",
    "# Render the mesh\n",
    "images = renderer(mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_check_x = torch.rand((3, 3))\n",
    "forward = lambda x: torch.sum(x ** 2, axis=1)\n",
    "\n",
    "num_grad = optimizer.compute_gradient_numerically(num_check_x, forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_check_x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the quadratic function\n",
    "def quadratic_function(points):\n",
    "    return torch.sum(points ** 2, dim=-1)\n",
    "\n",
    "# Known analytical gradients for the quadratic function\n",
    "def analytical_gradients(points):\n",
    "    return 2 * points\n",
    "\n",
    "# Define points for which to compute gradients\n",
    "points = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                       [4.0, 5.0, 6.0],\n",
    "                       [7.0, 8.0, 9.0]], requires_grad=True)\n",
    "\n",
    "# Compute the function output\n",
    "function_output = quadratic_function(points)\n",
    "\n",
    "# Compute analytical gradients\n",
    "true_gradients = analytical_gradients(points)\n",
    "\n",
    "# Compute gradients using autograd\n",
    "function_output.backward(torch.ones_like(function_output))\n",
    "autograd_gradients = points.grad\n",
    "\n",
    "# Compute gradients using the numerical method\n",
    "numerical_gradients = optimizer.compute_gradient_numerically(points, quadratic_function, delta=1e-2)\n",
    "\n",
    "# Compare numerical gradients to true gradients\n",
    "gradient_difference = torch.abs(numerical_gradients - true_gradients)\n",
    "\n",
    "print(\"True gradients:\\n\", true_gradients)\n",
    "print(\"Autograd gradients:\\n\", autograd_gradients)\n",
    "print(\"Numerical gradients:\\n\", numerical_gradients)\n",
    "print(\"Gradient difference:\\n\", gradient_difference)\n",
    "\n",
    "# Check if the numerical gradients are close to the true gradients\n",
    "assert torch.allclose(numerical_gradients, true_gradients, atol=1e-3), \"Numerical gradients do not match true gradients closely enough.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test vars\n",
    "\n",
    "volume_centers = torch.tensor([\n",
    "    [0.1, 0, 0.5], \n",
    "    [0.5, 0.2, 0], \n",
    "    [0.7, 0.1, 0.6], \n",
    "    [1, 1, .5], \n",
    "])\n",
    "\n",
    "scales = torch.tensor([1, 1, 1, .4])\n",
    "\n",
    "points = torch.tensor([\n",
    "    [0.5, 0.5, 0], \n",
    "    [1, 0, .5], \n",
    "])\n",
    "\n",
    "k = 7\n",
    "\n",
    "sdf_values = torch.rand((scales.shape[0], k, k ,k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the updated ShapeSampler class\n",
    "# shape_sampler = ShapeSampler(\"sphere\")\n",
    "# center = torch.tensor([0.0, 0.0, 0.0])\n",
    "# scale = 2.0\n",
    "\n",
    "# # Compute local SDF values\n",
    "# local_sdf_values = compute_local_sdf(shape_sampler, center, scale, grid_resolution=3)\n",
    "# print(local_sdf_values.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
