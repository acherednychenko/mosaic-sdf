{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from mosaic_sdf import MosaicSDF\n",
    "from shape_sampler import ShapeSampler\n",
    "from optimizer import MosaicSDFOptimizer\n",
    "from mosaic_sdf_visualizer import MosaicSDFVisualizer\n",
    "\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_mesh_path = 'data/cube.obj'\n",
    "teapot_mesh_path = 'data/utah_teapot.obj'\n",
    "cow_mesh_path = 'data/cow_mesh/cow.obj'\n",
    "\n",
    "cube_wireframe_path = 'data/cube_wireframe.obj'\n",
    "\n",
    "sdf_shape_path = teapot_mesh_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import os\n",
    "\n",
    "\n",
    "config = {   \n",
    "    'device': device,\n",
    "    # 'shape_sampler': shape_sampler,  # Adjust accordingly\n",
    "    'shape_path': os.path.abspath(sdf_shape_path),  # Adjust accordingly\n",
    "    \n",
    "    # mosaicSDF params\n",
    "    'grid_resolution': 7,\n",
    "    # 'n_grids': 1024,\n",
    "    # 'n_grids': 128,\n",
    "    # 'n_grids': 8,\n",
    "    'n_grids': tune.grid_search([ 512 ]),\n",
    "    'points_random_spread': tune.grid_search([.01, .03, .05]),\n",
    "\n",
    "    'val_points_random_spread': .03,\n",
    "    # 'mosaic_scale_multiplier': 3,\n",
    "    'mosaic_scale_multiplier': tune.grid_search([ 2, 3, 5 ]),\n",
    "    \n",
    "    # optimizer params\n",
    "    # 'lr': 1e-4,\n",
    "    'lr': tune.grid_search([ 1e-3, 1e-4]),\n",
    "    'weight_decay': 0.0,\n",
    "    \"b1\": tune.grid_search([0.5, 0.9]),\n",
    "    \"b2\": .999,\n",
    "\n",
    "    # lerp between l1 and l2 losses\n",
    "    'lambda_val': .1,\n",
    "    \n",
    "    \n",
    "    # optimization params\n",
    "    # 'n_epochs':  tune.choice([1, 4, 8, 16]),\n",
    "    # 'n_epochs':  tune.grid([ 8 ]),\n",
    "    \n",
    "    'n_epochs':  2,\n",
    "\n",
    "    'points_in_epoch': 4096,\n",
    "    'points_sample_size': 32,\n",
    "    # 'gradient_accumulation_steps': 1,\n",
    "    'gradient_accumulation_steps': tune.grid_search([1, 4, 8]),\n",
    "\n",
    "    'eval_every_nth_points': 512,\n",
    "    'val_size': 2048,\n",
    "    'points_sample_size_eval_scaler': 4, # can sample faster during eval\n",
    "\n",
    "    'project_name': 'mosaicSDF_tea_pot.03',\n",
    "    'log_to_wandb': True, \n",
    "    'log_to_console': False,\n",
    "    \n",
    "    # other debug stuff\n",
    "    'output_graph': False,\n",
    "    'points_random_sampling': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train import RunConfig, CheckpointConfig\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from ray.data import DataContext\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "# from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "# mlflow_tracking_uri = \"http://localhost:5000\"\n",
    "\n",
    "driver_ctx = DataContext.get_current()\n",
    "\n",
    "trainable_with_resources = tune.with_resources(MosaicSDFOptimizer, {\"cpu\": 10, \"gpu\": 1})\n",
    "\n",
    "wb_exclude = ['training_iteration',\n",
    "              'timestamp',\n",
    "              'time_since_restore',\n",
    "              'iterations_since_restore']\n",
    "\n",
    "tune_storage_path = f\"./out/tune/{config['project_name']}\"\n",
    "tune_storage_path = os.path.abspath(tune_storage_path)\n",
    "\n",
    "# experiment_name = 'mosaic_sdf_smoke'\n",
    "\n",
    "# print(f\"experiment_name: {experiment_name}\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    run_config=RunConfig(\n",
    "        storage_path=tune_storage_path, \n",
    "        name=config['project_name'],\n",
    "        stop={\"training_iteration\": config['n_epochs']},\n",
    "        callbacks= [\n",
    "         #   WandbLoggerCallback(project=\"hello_tune\", excludes=wb_exclude),\n",
    "            # MLflowLoggerCallback(\n",
    "            #         tracking_uri=mlflow_tracking_uri,\n",
    "            #         experiment_name=experiment_name,\n",
    "            #         save_artifact=False,\n",
    "            #     )\n",
    "         ],\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=10,\n",
    "            checkpoint_frequency=0,  #checkpoint disabled!\n",
    "            checkpoint_at_end=True\n",
    "        )),\n",
    "    \n",
    "    tune_config=tune.TuneConfig(\n",
    "        # num_samples=1,\n",
    "        # metric=\"test_loss_pixel\", \n",
    "        # mode=\"min\",\n",
    "        max_concurrent_trials=1,\n",
    "        # search_alg=algo,\n",
    "        scheduler=ASHAScheduler(metric='val_loss', mode=\"min\", grace_period=10),\n",
    "    ),\n",
    "    # param_space=train_config if continue_tune else tuning_config,\n",
    "    param_space=config\n",
    ")\n",
    "\n",
    "\n",
    "continue_tune = False\n",
    "if not continue_tune:\n",
    "    results = tuner.fit()\n",
    "else:\n",
    "    print('resuming')\n",
    "    restored_tuner = tune.Tuner.restore(\n",
    "        Checkpoint.from_directory(os.path.join(tune_storage_path, config['project_name'])).path,\n",
    "        trainable=trainable_with_resources,\n",
    "        # Re-specify the `param_space` to update the object references.\n",
    "        param_space=config,\n",
    "        resume_unfinished=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = None # load optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualizer = MosaicSDFVisualizer(optimizer.model, optimizer.shape_sampler, \n",
    "    device, template_mesh_path=cube_wireframe_path)#, requires_grad=False)\n",
    "\n",
    "shape_sampler = ShapeSampler.from_file(sdf_shape_path, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_vis import compare_shapes\n",
    "\n",
    "compare_shapes(shape_sampler, visualizer, 32, show_mosaic_grids=False,\n",
    "               show_gt_mesh=True, show_gt_sdf=False, show_mosaic_sdf=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_shapes(32, show_mosaic_grids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you're not using a data loader for training\n",
    "optimizer.train()  # Pass None or adjust `train` method to not require `train_loader`\n",
    "\n",
    "\n",
    "\n",
    "# I am also not sure autograd is what we need, how it works in this case at all?\n",
    "\n",
    "# # To save the optimized model\n",
    "# optimizer.save_checkpoint('path/to/save/checkpoint')\n",
    "\n",
    "# # To load an existing model\n",
    "# optimizer.load_checkpoint('path/to/existing/checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_shapes(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     with torch.no_grad():\n",
    "#         meshes = visualizer.create_state_meshes(\n",
    "#             show_mosaic_grids=False,\n",
    "#             show_target_mesh=False,\n",
    "#             resolution=16\n",
    "#             )\n",
    "        \n",
    "#         # Render the plotly figure\n",
    "#         fig = plot_scene({\n",
    "#             \"subplot1\": {\n",
    "#                 \"mesh\": meshes\n",
    "#             }\n",
    "#         })\n",
    "#         fig.show()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     resolution = 8\n",
    "#     grid_points = torch.stack(torch.meshgrid(\n",
    "#             torch.linspace(-1, 1, resolution),\n",
    "#             torch.linspace(-1, 1, resolution),\n",
    "#             torch.linspace(-1, 1, resolution)\n",
    "#         ), dim=-1).reshape(-1, 3)#.to(device)\n",
    "\n",
    "#     sdf_values = optimizer.model(grid_points.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_meshes._verts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from skimage.measure import marching_cubes\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.io import save_obj\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras,\n",
    "    PointLights,\n",
    "    RasterizationSettings,\n",
    "    MeshRenderer,\n",
    "    MeshRasterizer,\n",
    "    SoftPhongShader\n",
    ")\n",
    "mosaic_sdf = optimizer.model\n",
    "resolution = 16\n",
    "\n",
    "# Assuming 'mosaic_sdf' is your MosaicSDF instance and 'resolution' is the desired grid resolution\n",
    "grid_points = torch.stack(torch.meshgrid(\n",
    "    torch.linspace(-1, 1, resolution),\n",
    "    torch.linspace(-1, 1, resolution),\n",
    "    torch.linspace(-1, 1, resolution)\n",
    "), dim=-1).reshape(-1, 3).to(config['device'])\n",
    "\n",
    "# Get the SDF values at these points\n",
    "sdf_values = mosaic_sdf(grid_points).detach().cpu().numpy()\n",
    "sdf_volume = sdf_values.reshape(resolution, resolution, resolution)\n",
    "sdf_volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run marching cubes to get vertices, faces, and normals\n",
    "verts, faces, normals, _ = marching_cubes(sdf_volume, level=0)\n",
    "faces = faces + 1  # skimage has 0-indexed faces, while PyTorch3D expects 1-indexed\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "verts = torch.tensor(verts, dtype=torch.float32)\n",
    "faces = torch.tensor(faces, dtype=torch.int64)\n",
    "\n",
    "# Create a PyTorch3D mesh\n",
    "mesh = Meshes(verts=[verts], faces=[faces])\n",
    "\n",
    "# Initialize a renderer\n",
    "R, T = look_at_view_transform(2.7, 0, 90)\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
    "raster_settings = RasterizationSettings(image_size=512)\n",
    "lights = PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
    "\n",
    "renderer = MeshRenderer(\n",
    "    rasterizer=MeshRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
    "    shader=SoftPhongShader(device=device, cameras=cameras, lights=lights)\n",
    ")\n",
    "\n",
    "# Render the mesh\n",
    "images = renderer(mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_check_x = torch.rand((3, 3))\n",
    "forward = lambda x: torch.sum(x ** 2, axis=1)\n",
    "\n",
    "num_grad = optimizer.compute_gradient_numerically(num_check_x, forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_check_x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the quadratic function\n",
    "def quadratic_function(points):\n",
    "    return torch.sum(points ** 2, dim=-1)\n",
    "\n",
    "# Known analytical gradients for the quadratic function\n",
    "def analytical_gradients(points):\n",
    "    return 2 * points\n",
    "\n",
    "# Define points for which to compute gradients\n",
    "points = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                       [4.0, 5.0, 6.0],\n",
    "                       [7.0, 8.0, 9.0]], requires_grad=True)\n",
    "\n",
    "# Compute the function output\n",
    "function_output = quadratic_function(points)\n",
    "\n",
    "# Compute analytical gradients\n",
    "true_gradients = analytical_gradients(points)\n",
    "\n",
    "# Compute gradients using autograd\n",
    "function_output.backward(torch.ones_like(function_output))\n",
    "autograd_gradients = points.grad\n",
    "\n",
    "# Compute gradients using the numerical method\n",
    "numerical_gradients = optimizer.compute_gradient_numerically(points, quadratic_function, delta=1e-2)\n",
    "\n",
    "# Compare numerical gradients to true gradients\n",
    "gradient_difference = torch.abs(numerical_gradients - true_gradients)\n",
    "\n",
    "print(\"True gradients:\\n\", true_gradients)\n",
    "print(\"Autograd gradients:\\n\", autograd_gradients)\n",
    "print(\"Numerical gradients:\\n\", numerical_gradients)\n",
    "print(\"Gradient difference:\\n\", gradient_difference)\n",
    "\n",
    "# Check if the numerical gradients are close to the true gradients\n",
    "assert torch.allclose(numerical_gradients, true_gradients, atol=1e-3), \"Numerical gradients do not match true gradients closely enough.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test vars\n",
    "\n",
    "volume_centers = torch.tensor([\n",
    "    [0.1, 0, 0.5], \n",
    "    [0.5, 0.2, 0], \n",
    "    [0.7, 0.1, 0.6], \n",
    "    [1, 1, .5], \n",
    "])\n",
    "\n",
    "scales = torch.tensor([1, 1, 1, .4])\n",
    "\n",
    "points = torch.tensor([\n",
    "    [0.5, 0.5, 0], \n",
    "    [1, 0, .5], \n",
    "])\n",
    "\n",
    "k = 7\n",
    "\n",
    "sdf_values = torch.rand((scales.shape[0], k, k ,k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the updated ShapeSampler class\n",
    "# shape_sampler = ShapeSampler(\"sphere\")\n",
    "# center = torch.tensor([0.0, 0.0, 0.0])\n",
    "# scale = 2.0\n",
    "\n",
    "# # Compute local SDF values\n",
    "# local_sdf_values = compute_local_sdf(shape_sampler, center, scale, grid_resolution=3)\n",
    "# print(local_sdf_values.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
